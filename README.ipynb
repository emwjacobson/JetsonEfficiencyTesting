{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd06926c7f1321ca1fe5bb091ffa85bfd2f1967eb96b033dfa3a772fcfece283da3",
   "display_name": "Python 3.8.0 64-bit ('.venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f51cb7c77d18eeae37d8743e6a8965b321790527a9d46ec999dcb7b2a990bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Create a virtual environment for Python to run in:\n",
    "\n",
    "`$ python3.8 -m venv .venv`\n",
    "\n",
    "Activate the virtual environment\n",
    "\n",
    "`$ source .venv/bin/activate`\n",
    "\n",
    "Update pip and setuptools\n",
    "\n",
    "`$ pip install --upgrade pip setuptools`\n",
    "\n",
    "Install requirements\n",
    "\n",
    "`$ pip install -r requirements.txt`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Research\n",
    "\n",
    "The initial goal is to determine the different variables that we can change to see how effieiency changes.\n",
    "As of now, these are:\n",
    "- GPU Frequency\n",
    "- CPU Frequency\n",
    "- Memory Frequency\n",
    "- Matrix Size\n",
    "- Deep Learning Accelerators (DLAs)\n",
    "- Tensor Cores\n",
    "- Data Types\n",
    "\n",
    "\n",
    "## AGX Info\n",
    "\n",
    "For the AGX all combinations of the 14 GPU frequencies, square matrix sizes (from 64 to 2048 with steps of 64 (32 total tests)), enabling and disabling the tensor cores, as well as the 3 data types (half, float, double).\n",
    "\n",
    "### System Info\n",
    "\n",
    "```\n",
    "$ cat /etc/nv_tegra_release \n",
    "# R32 (release), REVISION: 4.4, GCID: 23942405, BOARD: t186ref, EABI: aarch64, DATE: Fri Oct 16 19:37:08 UTC 2020\n",
    "```\n",
    "\n",
    "```\n",
    "$ nvcc -V\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2019 NVIDIA Corporation\n",
    "Built on Wed_Oct_23_21:14:42_PDT_2019\n",
    "Cuda compilation tools, release 10.2, V10.2.89\n",
    "```\n",
    "\n",
    "## Nano Info\n",
    "\n",
    "**todo**\n",
    "\n",
    "### System Info\n",
    "\n",
    "```\n",
    "todo\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Benchmarking Procedures\n",
    "\n",
    "The `benchmark.cu` file is used for benchmarking the Jetson boards using various options.\n",
    "\n",
    "Before each test, the CPU min/max frequency is set to it's maximum frequency (can also be changed later for more power usage info).\n",
    "\n",
    "```\n",
    "AGX$ echo \"2265600\" | sudo tee /sys/devices/system/cpu/cpu0/cpufreq/scaling_{min,max}_freq\n",
    "```\n",
    "\n",
    "The GPU frequency is then set\n",
    "\n",
    "### AGX\n",
    "```\n",
    "# All available frequencies: 114750000 216750000 318750000 420750000 522750000 624750000 675750000 828750000 905250000 1032750000 1198500000 1236750000 1338750000 1377000000\n",
    "$ echo \"1377000000\" | sudo tee /sys/devices/17000000.gv11b/devfreq/17000000.gv11b/{min,max}_freq\n",
    "```\n",
    "\n",
    "### Nano\n",
    "```\n",
    "$ todo\n",
    "```\n",
    "\n",
    "**Note** On the AGX, the fan ramp speed needs to be changed to make the fan more responsive when set.\n",
    "\n",
    "```\n",
    "AGX$ echo \"5\" | sudo tee /sys/devices/pwm-fan/step_time\n",
    "```\n",
    "\n",
    "After the GPU and CPU frequencies have been set, the benchmark can be run.\n",
    "\n",
    "```\n",
    "$ sudo ./gpu_benchmark\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "import os\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "path = \"./data/AGX/\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_name in files:\n",
    "    temp = {\n",
    "        # Inputs\n",
    "        \"datatype\": \"\",\n",
    "        \"matrix_size\": -1,\n",
    "        \"tensor\": None,\n",
    "        \"gpu_frequency\": -1,\n",
    "\n",
    "        # Results\n",
    "        \"power_usage\": [],\n",
    "        \"flops\": -1,\n",
    "        \n",
    "        # Calculated Results\n",
    "        \"avg_power\": -1,\n",
    "        \"flops_per_watt\": -1\n",
    "    }\n",
    "    with open(path+file_name, \"r\") as f:\n",
    "        temp['datatype'], temp['matrix_size'], temp['tensor'], temp['gpu_frequency'] = file_name.split(\".\")[0].split(\"-\")[1:]\n",
    "        temp['matrix_size'] = float(temp['matrix_size'])\n",
    "        temp['tensor'] = True if temp['tensor'].lower() == \"tensor\" else False\n",
    "        temp['gpu_frequency'] = float(temp['gpu_frequency'])\n",
    "\n",
    "        file_data = f.readlines()\n",
    "\n",
    "        _, temp['power_usage'] = zip(*[d.strip().split(\",\") for d in file_data[:-1]])\n",
    "        temp['power_usage'] = list(map(float, temp['power_usage']))\n",
    "        temp['avg_power'] = sum(temp['power_usage'])/len(temp['power_usage'])\n",
    "\n",
    "        temp['flops'] = float(file_data[-1])\n",
    "\n",
    "        temp['flops_per_watt'] = temp['flops'] / temp['avg_power']\n",
    "    \n",
    "    data.append(temp)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(Dropdown(description='fixed1', options=('datatype', 'tensor', 'matrix_size', 'gpu_freque…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1307e479cd646afbd249e779d9036c0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(Dropdown(description='fixed1', options=('datatype', 'tensor', 'matrix_size', 'gpu_freque…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3d64ee55c604f33a06f99da83f10d38"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# BEGIN WIDGETS\n",
    "\n",
    "@interact\n",
    "def select_1(fixed1=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed2=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed3=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              gpu_frequency=[114750000, 216750000, 318750000, 420750000, 522750000, 624750000, 675750000, 828750000, 905250000, 1032750000, 1198500000, 1236750000, 1338750000, 1377000000],\n",
    "              matrix_size=np.arange(64, 2048, step=64),\n",
    "              tensor=[True, False],\n",
    "              datatype=[\"half\", \"float\", \"double\"],\n",
    "              x=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"],\n",
    "              y=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"]):\n",
    "\n",
    "    # We want to look for 3 of the 4 searchable options: datatype, tensor, matrix_size, and gpu_frequency\n",
    "    search = {}\n",
    "    search[fixed1] = eval(fixed1)\n",
    "    search[fixed2] = eval(fixed2)\n",
    "    search[fixed3] = eval(fixed3)\n",
    "\n",
    "    results = [d for d in data if search.items() <= d.items()]\n",
    "    x, y = zip(*sorted([(r[x], r[y]) for r in results], key=lambda d : d[0]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xticks(np.arange(0, 2304, step=256))\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    plt.show()\n",
    "    # set_data()\n",
    "\n",
    "@interact\n",
    "def select_2(fixed1=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed2=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed3=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              gpu_frequency=[114750000, 216750000, 318750000, 420750000, 522750000, 624750000, 675750000, 828750000, 905250000, 1032750000, 1198500000, 1236750000, 1338750000, 1377000000],\n",
    "              matrix_size=np.arange(64, 2048, step=64),\n",
    "              tensor=[True, False],\n",
    "              datatype=[\"half\", \"float\", \"double\"],\n",
    "              x=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"],\n",
    "              y=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"]):\n",
    "\n",
    "    # We want to look for 3 of the 4 searchable options: datatype, tensor, matrix_size, and gpu_frequency\n",
    "    search = {}\n",
    "    search[fixed1] = eval(fixed1)\n",
    "    search[fixed2] = eval(fixed2)\n",
    "    search[fixed3] = eval(fixed3)\n",
    "\n",
    "    results = [d for d in data if search.items() <= d.items()]\n",
    "    x, y = zip(*sorted([(r[x], r[y]) for r in results], key=lambda d : d[0]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xticks(np.arange(0, 2304, step=256))\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# END WIDGETS"
   ]
  },
  {
   "source": [
    "The difference in efficiencies with tensor cores enables and disabled."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "float 1377000000.0 64.0 0.9294675997623285\nfloat 1377000000.0 128.0 1.0100375330024962\nfloat 1377000000.0 192.0 0.993580271289533\nfloat 1377000000.0 256.0 1.0004127182593558\nfloat 1377000000.0 320.0 0.9931683155671189\nfloat 1377000000.0 384.0 0.9982361431035907\nfloat 1377000000.0 448.0 1.0011837552417064\nfloat 1377000000.0 512.0 1.0016213681790727\nfloat 1377000000.0 576.0 0.9949193534240564\nfloat 1377000000.0 640.0 0.9936327318282169\nfloat 1377000000.0 704.0 1.0003020751877894\nfloat 1377000000.0 768.0 0.9960521623572154\nfloat 1377000000.0 832.0 1.0094845347702088\nfloat 1377000000.0 896.0 1.001199361354049\nfloat 1377000000.0 960.0 0.9970241841484568\nfloat 1377000000.0 1024.0 1.0055879846252083\nfloat 1377000000.0 1088.0 0.9972686160760723\nfloat 1377000000.0 1152.0 0.9989444972230163\nfloat 1377000000.0 1216.0 1.0008076632295422\nfloat 1377000000.0 1280.0 1.0064465739487443\nfloat 1377000000.0 1344.0 0.9897112892161065\nfloat 1377000000.0 1408.0 1.0027391306962667\nfloat 1377000000.0 1472.0 0.9979966223368636\nfloat 1377000000.0 1536.0 0.9975413475384689\nfloat 1377000000.0 1600.0 0.9920528046428654\nfloat 1377000000.0 1664.0 1.0015476224285242\nfloat 1377000000.0 1728.0 1.001195217641545\nfloat 1377000000.0 1792.0 1.0001394725625345\nfloat 1377000000.0 1856.0 1.0030833658927945\nfloat 1377000000.0 1920.0 0.9784351659437291\nfloat 1377000000.0 1984.0 0.972593420992484\nfloat 1377000000.0 2048.0 0.9985777280456849\n"
     ]
    }
   ],
   "source": [
    "# [114750000, 216750000, 318750000, 420750000, 522750000, 624750000, 675750000, 828750000, 905250000, 1032750000, 119850000, 1236750000, 133875000, 1377000000]\n",
    "search_tensor = {\n",
    "    \"datatype\": \"float\",\n",
    "    \"gpu_frequency\": 1377000000,\n",
    "    \"tensor\": True\n",
    "}\n",
    "\n",
    "search_nontensor = {\n",
    "    \"datatype\": \"float\",\n",
    "    \"gpu_frequency\": 1377000000,\n",
    "    \"tensor\": False\n",
    "}\n",
    "\n",
    "results_tensor = [d for d in data if search_tensor.items() <= d.items()]\n",
    "results_nontensor = [d for d in data if search_nontensor.items() <= d.items()]\n",
    "\n",
    "for m_size in range(64, 2049, 64):\n",
    "    t = next(r for r in results_tensor if r['matrix_size'] == m_size)\n",
    "    nt = next(r for r in results_nontensor if r['matrix_size'] == m_size)\n",
    "\n",
    "    res = t['flops_per_watt']/nt['flops_per_watt']\n",
    "    \n",
    "    print(t['datatype'], t['gpu_frequency'], t['matrix_size'], res)"
   ]
  }
 ]
}