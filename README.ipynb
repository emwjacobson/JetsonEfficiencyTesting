{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd03f51cb7c77d18eeae37d8743e6a8965b321790527a9d46ec999dcb7b2a990bf5",
   "display_name": "Python 3.8.0 64-bit ('.venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f51cb7c77d18eeae37d8743e6a8965b321790527a9d46ec999dcb7b2a990bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Create a virtual environment for Python to run in:\n",
    "\n",
    "`$ python3.8 -m venv .venv`\n",
    "\n",
    "Activate the virtual environment\n",
    "\n",
    "`$ source .venv/bin/activate`\n",
    "\n",
    "Update pip and setuptools\n",
    "\n",
    "`$ pip install --upgrade pip setuptools`\n",
    "\n",
    "Install requirements\n",
    "\n",
    "`$ pip install -r requirements.txt`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Research\n",
    "\n",
    "The initial goal is to determine the different variables that we can change to see how effieiency changes.\n",
    "As of now, these are:\n",
    "- GPU Frequency (14)\n",
    "- CPU Frequency\n",
    "- Memory Frequency\n",
    "- Matrix Size (128 to 2048, with steps of 128) (16)\n",
    "- Deep Learning Accelerators (DLAs)\n",
    "- Tensor Cores (2)\n",
    "- Data Types (Half, Float, Double) (3)\n",
    "\n",
    "Ideally the goal would be to test all combinations of them, but as there are over 30,000 combinations it's unreasonable.\n",
    "\n",
    "For the tests I chose to do all 14 of the GPU frequencies, Matrix sizes from 128 to 2048 with steps of 128 (16 total tests), with and without tensor cores, for 3 data tytpes (Half, Float, and Double). This gives 1344 tests.\n",
    "\n",
    "## AGX Info\n",
    "\n",
    "```\n",
    "$ cat /etc/nv_tegra_release \n",
    "# R32 (release), REVISION: 4.4, GCID: 23942405, BOARD: t186ref, EABI: aarch64, DATE: Fri Oct 16 19:37:08 UTC 2020\n",
    "```\n",
    "\n",
    "```\n",
    "$ nvcc -V\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2019 NVIDIA Corporation\n",
    "Built on Wed_Oct_23_21:14:42_PDT_2019\n",
    "Cuda compilation tools, release 10.2, V10.2.89\n",
    "```\n",
    "\n",
    "## Nano Info\n",
    "Todo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The `benchmark.cu` file is used for benchmarking the Jetson boards using various options.\n",
    "\n",
    "Before each test, the CPU min/max frequency is set to it's maximum frequency (can also be changed later for more power usage info).\n",
    "\n",
    "```\n",
    "$ echo \"2265600\" | sudo tee /sys/devices/system/cpu/cpu0/cpufreq/scaling_{min,max}_freq\n",
    "```\n",
    "\n",
    "The GPU frequency is then set\n",
    "\n",
    "AGX\n",
    "```\n",
    "$ echo \"1377000000\" | sudo tee /sys/devices/17000000.gv11b/devfreq/17000000.gv11b/{min,max}_freq\n",
    "```\n",
    "\n",
    "Nano\n",
    "```\n",
    "$ todo\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# TODO\n",
    "# https://mpl-interactions.readthedocs.io/en/latest/examples/mpl-sliders.html\n",
    "# https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6\n",
    "\n",
    "import os\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"./data/AGX/\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_name in files:\n",
    "    temp = {\n",
    "        # Inputs\n",
    "        \"datatype\": \"\",\n",
    "        \"matrix_size\": -1,\n",
    "        \"tensor\": None,\n",
    "        \"gpu_frequency\": -1,\n",
    "\n",
    "        # Results\n",
    "        \"power_usage\": [],\n",
    "        \"flops\": -1,\n",
    "        \n",
    "        # Calculated Results\n",
    "        \"avg_power\": -1,\n",
    "        \"flops_per_watt\": -1\n",
    "    }\n",
    "    with open(path+file_name, \"r\") as f:\n",
    "        temp['datatype'], temp['matrix_size'], temp['tensor'], temp['gpu_frequency'] = file_name.split(\".\")[0].split(\"-\")[1:]\n",
    "        temp['matrix_size'] = float(temp['matrix_size'])\n",
    "        temp['tensor'] = True if temp['tensor'].lower() == \"tensor\" else False\n",
    "        temp['gpu_frequency'] = float(temp['gpu_frequency'])\n",
    "\n",
    "        file_data = f.readlines()\n",
    "\n",
    "        _, temp['power_usage'] = zip(*[d.strip().split(\",\") for d in file_data[:-1]])\n",
    "        temp['power_usage'] = list(map(float, temp['power_usage']))\n",
    "        temp['avg_power'] = sum(temp['power_usage'])/len(temp['power_usage'])\n",
    "\n",
    "        temp['flops'] = float(file_data[-1])\n",
    "\n",
    "        temp['flops_per_watt'] = temp['flops'] / temp['avg_power']\n",
    "    \n",
    "    data.append(temp)\n",
    "\n",
    "search1 = {\n",
    "    \"datatype\": \"float\",\n",
    "    \"tensor\": True,\n",
    "    # \"matrix_size\": 2048,\n",
    "    \"gpu_frequency\": 1377000000\n",
    "}\n",
    "\n",
    "search2 = {\n",
    "    \"datatype\": \"float\",\n",
    "    \"tensor\": False,\n",
    "    # \"matrix_size\": 2048,\n",
    "    \"gpu_frequency\": 1377000000\n",
    "}\n",
    "\n",
    "results1 = [d for d in data if search1.items() <= d.items()]\n",
    "results2 = [d for d in data if search2.items() <= d.items()]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "x1, y1 = zip(*sorted([(r['matrix_size'], r['flops']) for r in results1], key=lambda d : d[0]))\n",
    "x2, y2 = zip(*sorted([(r['matrix_size'], r['flops']) for r in results2], key=lambda d : d[0]))\n",
    "ax[0].plot(x1, y1)\n",
    "ax[1].plot(x2, y2)\n",
    "\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4439da9ed6224bd2b8c3669ac42f3421"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}