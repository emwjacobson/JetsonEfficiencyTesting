{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd06926c7f1321ca1fe5bb091ffa85bfd2f1967eb96b033dfa3a772fcfece283da3",
   "display_name": "Python 3.8.0 64-bit ('.venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f51cb7c77d18eeae37d8743e6a8965b321790527a9d46ec999dcb7b2a990bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Create a virtual environment for Python to run in:\n",
    "\n",
    "`$ python3.8 -m venv .venv`\n",
    "\n",
    "Activate the virtual environment\n",
    "\n",
    "`$ source .venv/bin/activate`\n",
    "\n",
    "Update pip and setuptools\n",
    "\n",
    "`$ pip install --upgrade pip setuptools`\n",
    "\n",
    "Install requirements\n",
    "\n",
    "`$ pip install -r requirements.txt`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Research\n",
    "\n",
    "The initial goal is to determine the different variables that we can change to see how effieiency changes.\n",
    "As of now, these are:\n",
    "- GPU Frequency (14)\n",
    "- CPU Frequency\n",
    "- Memory Frequency\n",
    "- Matrix Size (128 to 2048, with steps of 128) (16)\n",
    "- Deep Learning Accelerators (DLAs)\n",
    "- Tensor Cores (2)\n",
    "- Data Types (Half, Float, Double) (3)\n",
    "\n",
    "Ideally the goal would be to test all combinations of them, but as there are over 30,000 combinations it's unreasonable.\n",
    "\n",
    "For the tests I chose to do all 14 of the GPU frequencies, Matrix sizes from 128 to 2048 with steps of 128 (16 total tests), with and without tensor cores, for 3 data tytpes (Half, Float, and Double). This gives 1344 tests.\n",
    "\n",
    "## AGX Info\n",
    "\n",
    "```\n",
    "$ cat /etc/nv_tegra_release \n",
    "# R32 (release), REVISION: 4.4, GCID: 23942405, BOARD: t186ref, EABI: aarch64, DATE: Fri Oct 16 19:37:08 UTC 2020\n",
    "```\n",
    "\n",
    "```\n",
    "$ nvcc -V\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2019 NVIDIA Corporation\n",
    "Built on Wed_Oct_23_21:14:42_PDT_2019\n",
    "Cuda compilation tools, release 10.2, V10.2.89\n",
    "```\n",
    "\n",
    "## Nano Info\n",
    "Todo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Benchmarking Procedures\n",
    "\n",
    "The `benchmark.cu` file is used for benchmarking the Jetson boards using various options.\n",
    "\n",
    "Before each test, the CPU min/max frequency is set to it's maximum frequency (can also be changed later for more power usage info).\n",
    "\n",
    "```\n",
    "$ echo \"2265600\" | sudo tee /sys/devices/system/cpu/cpu0/cpufreq/scaling_{min,max}_freq\n",
    "```\n",
    "\n",
    "The GPU frequency is then set\n",
    "\n",
    "AGX\n",
    "```\n",
    "# All available frequencies: 114750000 216750000 318750000 420750000 522750000 624750000 675750000 828750000 905250000 1032750000 1198500000 1236750000 1338750000 1377000000\n",
    "$ echo \"1377000000\" | sudo tee /sys/devices/17000000.gv11b/devfreq/17000000.gv11b/{min,max}_freq\n",
    "```\n",
    "\n",
    "Nano\n",
    "```\n",
    "$ todo\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "import os\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "path = \"./data/AGX/\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_name in files:\n",
    "    temp = {\n",
    "        # Inputs\n",
    "        \"datatype\": \"\",\n",
    "        \"matrix_size\": -1,\n",
    "        \"tensor\": None,\n",
    "        \"gpu_frequency\": -1,\n",
    "\n",
    "        # Results\n",
    "        \"power_usage\": [],\n",
    "        \"flops\": -1,\n",
    "        \n",
    "        # Calculated Results\n",
    "        \"avg_power\": -1,\n",
    "        \"flops_per_watt\": -1\n",
    "    }\n",
    "    with open(path+file_name, \"r\") as f:\n",
    "        temp['datatype'], temp['matrix_size'], temp['tensor'], temp['gpu_frequency'] = file_name.split(\".\")[0].split(\"-\")[1:]\n",
    "        temp['matrix_size'] = float(temp['matrix_size'])\n",
    "        temp['tensor'] = True if temp['tensor'].lower() == \"tensor\" else False\n",
    "        temp['gpu_frequency'] = float(temp['gpu_frequency'])\n",
    "\n",
    "        file_data = f.readlines()\n",
    "\n",
    "        _, temp['power_usage'] = zip(*[d.strip().split(\",\") for d in file_data[:-1]])\n",
    "        temp['power_usage'] = list(map(float, temp['power_usage']))\n",
    "        temp['avg_power'] = sum(temp['power_usage'])/len(temp['power_usage'])\n",
    "\n",
    "        temp['flops'] = float(file_data[-1])\n",
    "\n",
    "        temp['flops_per_watt'] = temp['flops'] / temp['avg_power']\n",
    "    \n",
    "    data.append(temp)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(Dropdown(description='fixed1', options=('datatype', 'tensor', 'matrix_size', 'gpu_freque…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71581eb9ecb54bb49a2c64e8adb16dcc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(Dropdown(description='fixed1', options=('datatype', 'tensor', 'matrix_size', 'gpu_freque…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6b6d464b3ad4f59835ac6610725cac9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# BEGIN WIDGETS\n",
    "\n",
    "@interact\n",
    "def select_1(fixed1=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed2=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed3=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              gpu_frequency=[114750000, 216750000, 318750000, 420750000, 522750000, 624750000, 675750000, 828750000, 905250000, 1032750000, 1198500000, 1236750000, 1338750000, 1377000000],\n",
    "              matrix_size=np.arange(64, 2048, step=64),\n",
    "              tensor=[True, False],\n",
    "              datatype=[\"half\", \"float\", \"double\"],\n",
    "              x=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"],\n",
    "              y=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"]):\n",
    "\n",
    "    # We want to look for 3 of the 4 searchable options: datatype, tensor, matrix_size, and gpu_frequency\n",
    "    search = {}\n",
    "    search[fixed1] = eval(fixed1)\n",
    "    search[fixed2] = eval(fixed2)\n",
    "    search[fixed3] = eval(fixed3)\n",
    "\n",
    "    results = [d for d in data if search.items() <= d.items()]\n",
    "    x, y = zip(*sorted([(r[x], r[y]) for r in results], key=lambda d : d[0]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xticks(np.arange(0, 2304, step=256))\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    plt.show()\n",
    "    # set_data()\n",
    "\n",
    "@interact\n",
    "def select_2(fixed1=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed2=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              fixed3=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\"],\n",
    "              gpu_frequency=[114750000, 216750000, 318750000, 420750000, 522750000, 624750000, 675750000, 828750000, 905250000, 1032750000, 1198500000, 1236750000, 1338750000, 1377000000],\n",
    "              matrix_size=np.arange(64, 2048, step=64),\n",
    "              tensor=[True, False],\n",
    "              datatype=[\"half\", \"float\", \"double\"],\n",
    "              x=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"],\n",
    "              y=[\"datatype\", \"tensor\", \"matrix_size\", \"gpu_frequency\", \"avg_power\", \"flops\", \"flops_per_watt\"]):\n",
    "\n",
    "    # We want to look for 3 of the 4 searchable options: datatype, tensor, matrix_size, and gpu_frequency\n",
    "    search = {}\n",
    "    search[fixed1] = eval(fixed1)\n",
    "    search[fixed2] = eval(fixed2)\n",
    "    search[fixed3] = eval(fixed3)\n",
    "\n",
    "    results = [d for d in data if search.items() <= d.items()]\n",
    "    x, y = zip(*sorted([(r[x], r[y]) for r in results], key=lambda d : d[0]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xticks(np.arange(0, 2304, step=256))\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# END WIDGETS"
   ]
  },
  {
   "source": [
    "The difference in efficiencies with tensor cores enables and disabled."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "float 1377000000.0 64.0 0.9294675997623285\nfloat 1377000000.0 128.0 1.0100375330024962\nfloat 1377000000.0 192.0 0.993580271289533\nfloat 1377000000.0 256.0 1.0004127182593558\nfloat 1377000000.0 320.0 0.9931683155671189\nfloat 1377000000.0 384.0 0.9982361431035907\nfloat 1377000000.0 448.0 1.0011837552417064\nfloat 1377000000.0 512.0 1.0016213681790727\nfloat 1377000000.0 576.0 0.9949193534240564\nfloat 1377000000.0 640.0 0.9936327318282169\nfloat 1377000000.0 704.0 1.0003020751877894\nfloat 1377000000.0 768.0 0.9960521623572154\nfloat 1377000000.0 832.0 1.0094845347702088\nfloat 1377000000.0 896.0 1.001199361354049\nfloat 1377000000.0 960.0 0.9970241841484568\nfloat 1377000000.0 1024.0 1.0055879846252083\nfloat 1377000000.0 1088.0 0.9972686160760723\nfloat 1377000000.0 1152.0 0.9989444972230163\nfloat 1377000000.0 1216.0 1.0008076632295422\nfloat 1377000000.0 1280.0 1.0064465739487443\nfloat 1377000000.0 1344.0 0.9897112892161065\nfloat 1377000000.0 1408.0 1.0027391306962667\nfloat 1377000000.0 1472.0 0.9979966223368636\nfloat 1377000000.0 1536.0 0.9975413475384689\nfloat 1377000000.0 1600.0 0.9920528046428654\nfloat 1377000000.0 1664.0 1.0015476224285242\nfloat 1377000000.0 1728.0 1.001195217641545\nfloat 1377000000.0 1792.0 1.0001394725625345\nfloat 1377000000.0 1856.0 1.0030833658927945\nfloat 1377000000.0 1920.0 0.9784351659437291\nfloat 1377000000.0 1984.0 0.972593420992484\nfloat 1377000000.0 2048.0 0.9985777280456849\n"
     ]
    }
   ],
   "source": [
    "# [114750000, 216750000, 318750000, 420750000, 522750000, 624750000, 675750000, 828750000, 905250000, 1032750000, 119850000, 1236750000, 133875000, 1377000000]\n",
    "search_tensor = {\n",
    "    \"datatype\": \"float\",\n",
    "    \"gpu_frequency\": 1377000000,\n",
    "    \"tensor\": True\n",
    "}\n",
    "\n",
    "search_nontensor = {\n",
    "    \"datatype\": \"float\",\n",
    "    \"gpu_frequency\": 1377000000,\n",
    "    \"tensor\": False\n",
    "}\n",
    "\n",
    "results_tensor = [d for d in data if search_tensor.items() <= d.items()]\n",
    "results_nontensor = [d for d in data if search_nontensor.items() <= d.items()]\n",
    "\n",
    "for m_size in range(64, 2049, 64):\n",
    "    t = next(r for r in results_tensor if r['matrix_size'] == m_size)\n",
    "    nt = next(r for r in results_nontensor if r['matrix_size'] == m_size)\n",
    "\n",
    "    res = t['flops_per_watt']/nt['flops_per_watt']\n",
    "    \n",
    "    print(t['datatype'], t['gpu_frequency'], t['matrix_size'], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}