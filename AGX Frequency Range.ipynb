{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('.venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f51cb7c77d18eeae37d8743e6a8965b321790527a9d46ec999dcb7b2a990bf5"
   }
  },
  "interpreter": {
   "hash": "3f51cb7c77d18eeae37d8743e6a8965b321790527a9d46ec999dcb7b2a990bf5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Create a virtual environment for Python to run in:\n",
    "\n",
    "`$ python3.8 -m venv .venv`\n",
    "\n",
    "Activate the virtual environment\n",
    "\n",
    "`$ source .venv/bin/activate`\n",
    "\n",
    "Update pip and setuptools\n",
    "\n",
    "`$ pip install --upgrade pip setuptools`\n",
    "\n",
    "Install requirements\n",
    "\n",
    "`$ pip install -r requirements.txt`\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Research\n",
    "\n",
    "The initial goal is to determine the different variables that we can change to see how effieiency changes.\n",
    "As of now, these are:\n",
    "- GPU Frequency\n",
    "- CPU Frequency\n",
    "- Memory Frequency\n",
    "- Matrix Size\n",
    "- Deep Learning Accelerators (DLAs)\n",
    "- Tensor Cores\n",
    "- Data Types\n",
    "\n",
    "\n",
    "## AGX Info\n",
    "\n",
    "For the AGX all combinations of the 14 GPU frequencies, square matrix sizes (from 64 to 2048 with steps of 64 (32 total tests)), enabling and disabling the tensor cores, as well as the 3 data types (half, float, double).\n",
    "\n",
    "### System Info\n",
    "\n",
    "```\n",
    "$ cat /etc/nv_tegra_release \n",
    "# R32 (release), REVISION: 4.4, GCID: 23942405, BOARD: t186ref, EABI: aarch64, DATE: Fri Oct 16 19:37:08 UTC 2020\n",
    "```\n",
    "\n",
    "```\n",
    "$ nvcc -V\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2019 NVIDIA Corporation\n",
    "Built on Wed_Oct_23_21:14:42_PDT_2019\n",
    "Cuda compilation tools, release 10.2, V10.2.89\n",
    "```\n",
    "\n",
    "## Nano Info\n",
    "\n",
    "**todo**\n",
    "\n",
    "### System Info\n",
    "\n",
    "```\n",
    "todo\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmarking Procedures\n",
    "\n",
    "The `benchmark.cu` file is used for benchmarking the Jetson boards using various options.\n",
    "\n",
    "Before each test, the CPU min/max frequency is set to it's maximum frequency (can also be changed later for more power usage info).\n",
    "\n",
    "```\n",
    "AGX$ echo \"2265600\" | sudo tee /sys/devices/system/cpu/cpu0/cpufreq/scaling_{min,max}_freq\n",
    "```\n",
    "\n",
    "The GPU frequency is then set\n",
    "\n",
    "### AGX\n",
    "```\n",
    "# All available frequencies: 114750000 216750000 318750000 420750000 522750000 624750000 675750000 828750000 905250000 1032750000 1198500000 1236750000 1338750000 1377000000\n",
    "$ echo \"1377000000\" | sudo tee /sys/devices/17000000.gv11b/devfreq/17000000.gv11b/{min,max}_freq\n",
    "```\n",
    "\n",
    "### Nano\n",
    "```\n",
    "$ todo\n",
    "```\n",
    "\n",
    "**Note** On the AGX, the fan ramp speed needs to be changed to make the fan more responsive when set.\n",
    "\n",
    "```\n",
    "AGX$ echo \"5\" | sudo tee /sys/devices/pwm-fan/step_time\n",
    "```\n",
    "\n",
    "After the GPU and CPU frequencies have been set, the benchmark can be run.\n",
    "\n",
    "```\n",
    "$ sudo ./gpu_benchmark\n",
    "```\n",
    "\n",
    "\n",
    "# TODO\n",
    "- 905 MHz and 1.377 GHz\n",
    "- Start work on Nano\n",
    "- Triton Inference on AGX/Nano"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "import os\n",
    "\n",
    "path = \"./data/AGX/\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_name in files:\n",
    "    temp = {\n",
    "        # Inputs\n",
    "        \"device\": \"\",\n",
    "        \"datatype\": \"\",\n",
    "        \"matrix_size\": -1,\n",
    "        \"tensor\": None,\n",
    "        \"gpu_frequency\": -1,\n",
    "\n",
    "        # Results\n",
    "        \"power_usage\": [],\n",
    "        \"flops\": -1,\n",
    "        \n",
    "        # Calculated Results\n",
    "        \"avg_power\": -1,\n",
    "        \"flops_per_watt\": -1\n",
    "    }\n",
    "    with open(path+file_name, \"r\") as f:\n",
    "        temp['device'], temp['datatype'], temp['matrix_size'], temp['tensor'], temp['gpu_frequency'] = file_name.split(\".\")[0].split(\"-\")\n",
    "        temp['matrix_size'] = float(temp['matrix_size'])\n",
    "        temp['tensor'] = True if temp['tensor'].lower() == \"tensor\" else False\n",
    "        temp['gpu_frequency'] = float(temp['gpu_frequency'])\n",
    "\n",
    "        file_data = f.readlines()\n",
    "\n",
    "        _, temp['power_usage'] = zip(*[d.strip().split(\",\") for d in file_data[:-1]])\n",
    "        temp['power_usage'] = list(map(float, temp['power_usage']))\n",
    "        temp['avg_power'] = sum(temp['power_usage'])/len(temp['power_usage'])\n",
    "\n",
    "        temp['flops'] = float(file_data[-1])\n",
    "\n",
    "        temp['flops_per_watt'] = temp['flops'] / temp['avg_power']\n",
    "    \n",
    "    data.append(temp)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "plt.ion()\n",
    "\n",
    "datatype = widgets.Dropdown(options=[\"half\", \"float\", \"double\"], value=\"float\", description=\"Datatype\")\n",
    "y_opt = widgets.Dropdown(options=[\"avg_power\", \"flops\", \"flops_per_watt\"], value=\"flops_per_watt\", description=\"y axis\")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5), sharey=True, sharex=True)\n",
    "\n",
    "search_tensor = {\n",
    "    \"datatype\": datatype.value,\n",
    "    \"gpu_frequency\": 0,\n",
    "    \"tensor\": True\n",
    "}\n",
    "\n",
    "search_nontensor = {\n",
    "    \"datatype\": datatype.value,\n",
    "    \"gpu_frequency\": 0,\n",
    "    \"tensor\": False\n",
    "}\n",
    "\n",
    "search_x = \"matrix_size\"\n",
    "search_y = y_opt.value\n",
    "\n",
    "def refresh_values():\n",
    "    for idx, f in enumerate([114750000, 216750000, 318750000, 420750000, 522750000, 624750000, 675750000, 828750000, 905250000, 1032750000, 1198500000, 1236750000, 1338750000, 1377000000]):\n",
    "        search_tensor[\"gpu_frequency\"] = f\n",
    "        search_nontensor[\"gpu_frequency\"] = f\n",
    "        filtered_tensor = [d for d in data if search_tensor.items() <= d.items()]\n",
    "        filtered_nontensor = [d for d in data if search_nontensor.items() <= d.items()]\n",
    "        x, y = [[],[]], [[],[]]\n",
    "        x[0], y[0] = zip(*sorted([(r[search_x], r[search_y]) for r in filtered_tensor], key=lambda d : d[0]))\n",
    "        x[1], y[1] = zip(*sorted([(r[search_x], r[search_y]) for r in filtered_nontensor], key=lambda d : d[0]))\n",
    "        for i in range(2):\n",
    "            ax[i].plot(x[i], y[i], label=f\"{f/1e9:.2f} GHz\", linestyle='--' if idx % 2 else '-')\n",
    "            ax[i].set_title(f\"Tensor Cores {'Enabled' if i == 0 else 'Disabled'}\")\n",
    "            ax[i].legend(loc=\"upper left\")\n",
    "            ax[i].set_xticks(np.arange(0, 2049, 128))\n",
    "\n",
    "def change_datatype(change):\n",
    "    search_tensor[\"datatype\"] = change[\"new\"]\n",
    "    search_nontensor[\"datatype\"] = change[\"new\"]\n",
    "    ax[0].clear()\n",
    "    ax[1].clear()\n",
    "    refresh_values()\n",
    "\n",
    "def update_y(change):\n",
    "    global search_y\n",
    "    search_y = change[\"new\"]\n",
    "    ax[0].clear()\n",
    "    ax[1].clear()\n",
    "    refresh_values()\n",
    "\n",
    "y_opt.observe(update_y, names=\"value\")\n",
    "datatype.observe(change_datatype, names=\"value\")\n",
    "\n",
    "display(\n",
    "    widgets.HBox([\n",
    "        widgets.VBox([datatype]),\n",
    "        widgets.VBox([y_opt]),\n",
    "        widgets.VBox([output])\n",
    "    ])\n",
    ")\n",
    "\n",
    "refresh_values()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-i0rrlt28 because the default path (/home/emerson/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a141e0019784712802d19d2c665b3c5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(VBox(children=(Dropdown(description='Datatype', index=1, options=('half', 'float', 'double'), v…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8245c8a5d6a4153b5f95f89b0e74578"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ]
}