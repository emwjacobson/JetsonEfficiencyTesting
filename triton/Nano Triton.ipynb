{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frequency = \"921600000\"\n",
    "\n",
    "# Batch Size,Concurrency,Inferences/Second,Client Send,Network+Server Send/Recv,Server Queue,Server Compute Input,Server Compute Infer,Server Compute Output,Client Recv,p50 latency,p90 latency,p95 latency,p99 latency\n",
    "data = []\n",
    "power_data = []\n",
    "timings = []\n",
    "\n",
    "with open(f\"data/{frequency}_data.csv\", \"r\") as f:\n",
    "  data = [l.strip().split(\",\") for l in f.readlines()[1:]]\n",
    "\n",
    "with open(f\"data/{frequency}_power.csv\", \"r\") as f:\n",
    "  power_data = [l.strip().split(\",\") for l in f.readlines()]\n",
    "\n",
    "with open(f\"data/{frequency}_timings.csv\", \"r\") as f:\n",
    "  timings = [l.strip().split(\",\") for l in f.readlines()[1:]]\n",
    "\n",
    "\n",
    "for start, stop, batch_size in timings:\n",
    "  power = [p for p in power_data if p[0] > start and p[0] < stop]\n",
    "  d = [d for d in data if d[0] == batch_size][0]\n",
    "  avg_power = sum([float(r[1]) for r in power])/len(power)\n",
    "  sec_per_inference = 1/float(d[2])\n",
    "  watt_per_inference = avg_power * sec_per_inference\n",
    "\n",
    "  print(batch_size, avg_power, watt_per_inference)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 8.07777777777778 0.20712250712250715\n",
      "2 8.005555555555555 0.1803053053053053\n",
      "3 7.788888888888888 0.1778285134449518\n",
      "4 6.531578947368421 0.13607456140350876\n",
      "5 6.566666666666667 0.1397163120567376\n",
      "6 6.572222222222222 0.1369212962962963\n",
      "7 6.655555555555555 0.13982259570494862\n",
      "8 6.527777777777777 0.1274956597222222\n",
      "9 6.427777777777778 0.13225880201188844\n",
      "10 6.436842105263158 0.12378542510121458\n",
      "11 6.555555555555555 0.12955643390426\n",
      "12 6.533333333333333 0.12373737373737374\n",
      "13 6.477777777777778 0.12457264957264957\n",
      "14 6.578947368421052 0.1305346700083542\n",
      "15 6.5777777777777775 0.1289760348583878\n",
      "16 6.455555555555556 0.11866830065359478\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "c1c4723ef3ea85fcb5cf75c36bc44b04a67d933a7e139491e9a5ad96775208a7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}